{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inscrivez ici vos noms et prénoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Régression linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Exemple 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.random((1000, 3))\n",
    "Y = 3 * X[:, 0] - 2 * X[:, 1] + X[:, 2] + np.random.random(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisez un modèle capable de prédire Y en fonction de X. On ne sera pas obligé de prendre en compte l'overfitting dans le cas présent.\n",
    "Il est bien entendu interdit de rentrer les coefficients à la main\n",
    "\n",
    "Utilisez :\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecrivez votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Exemple 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.random((1000, 3))\n",
    "Y = 4 * X[:, 0] ** 2 + X[:, 1] + X[:, 2] + np.random.random(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisez un modèle capable de prédire Y en fonction de X. On ne sera pas obligé de prendre en compte l'overfitting dans le cas présent.\n",
    "Important : une simple régression linéaire ne fonctionnera pas ici, il faudra utiliser un peu de feature engineering :\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "\n",
    "Utilisez :\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecrivez votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.random((1000, 3))\n",
    "Y = X[:, 0] + X[:, 1] + X[:, 2] + np.random.random(1000) > 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisez un modèle capable de prédire Y en fonction de X. On ne sera pas obligé de prendre en compte l'overfitting dans le cas présent.\n",
    "\n",
    "Utilisez :\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Iris data set et K-Nearest Neighbors\n",
    "\n",
    "Le set des Iris est un classique en machine learning, on a un petit jeu de données (150 éléments) avec 3 variétés d'Iris (Setosa, Versicolour, Virginica) et 4 \"features\" : largeur et longueur des pétales et des sépales.\n",
    "\n",
    "On cherche à développer un classifieur qui soit capable de déterminer de quel type de fleur il s'agit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "print('#' * 25)\n",
    "print(iris.keys())\n",
    "print('#' * 25)\n",
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "# Source : https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "\n",
    "plt.figure(2, figsize=(8, 6))\n",
    "plt.clf()\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1,\n",
    "            edgecolor='k')\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sépare les données en jeu de donnée d'entrainement et de test.\n",
    "A noter que suivant le cas, il peut être important de mélanger les données. Ici on privilégie la simplicité et le fait d'être sur que les 3 classes sont équitablement représentées dans les deux jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.concatenate((iris['data'][:40, :], iris['data'][50:90, :], iris['data'][100:140, :]), axis = 0)\n",
    "training_target = np.concatenate((iris['target'][:40], iris['target'][50:90], iris['target'][100:140]), axis = 0)\n",
    "\n",
    "test_data = np.concatenate((iris['data'][40:50, :], iris['data'][90:100, :], iris['data'][140:, :]), axis = 0)\n",
    "test_target = np.concatenate((iris['target'][40:50], iris['target'][90:100], iris['target'][140:]), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les dimensions pour vérfier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_data.shape)\n",
    "print(training_target.shape)\n",
    "print(test_data.shape)\n",
    "print(test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vous de jouer ! Construisez un classifier en utilisant le training set, et tester le, en prédisant à partir des données de test_data.\n",
    "\n",
    "Indiquez votre prédiction dans la variable prediction pour pouvoir vérifier le taux de bonne réponses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.array([0] * len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pourcentage of correct answer : {100*(prediction == test_target).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-NN et données générées\n",
    "\n",
    "On travaille maintenant avec des données générées. Il n'y a pas de code à écrire ici, il s'agit de comprendre le code et d'analyser les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def generate_data_set(nb_class, nb_features, nb_elements = 1000, test_ratio = 0.2, first_feature_scale = 1):\n",
    "    \"\"\" La fonction generate_data_set prend en arguments 5 paramètres :\n",
    "        - le nombre de classes\n",
    "        - le nombre de features\n",
    "        - le nombre d'éléments (défaut 1000)\n",
    "        - le test_ratio, ie le nombre d'éléments à mettre dans le jeu de données de test\n",
    "        - le first feature scale, un facteur d'échelle appliqué au premier feature\n",
    "        \n",
    "    La classe est entièrement déterminé par le premier feature.\n",
    "    Les feature sont générés selon un loi uniforme entre 0 et 1\n",
    "    \n",
    "    Renvoit 4 éléments : train_data, train_y, test_data, test_y\n",
    "    \"\"\"\n",
    "    \n",
    "    all_data = np.random.random((nb_elements, nb_features))\n",
    "    y = np.floor(all_data[:, 0] * nb_class).astype(np.int32)\n",
    "    \n",
    "    all_data[:, 0] *= first_feature_scale\n",
    "    \n",
    "    nb_train = int((1 - test_ratio) * nb_elements)\n",
    "    \n",
    "    return all_data[:nb_train, :], y[:nb_train], all_data[nb_train:, :], y[nb_train:]\n",
    "    \n",
    "train_data, train_y, test_data, test_y = generate_data_set(1000, 5)\n",
    "\n",
    "print((train_data.shape, train_y.shape, test_data.shape, test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(generate_data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par comparer les résultats de l'algorithme en faisant varier le nombre de features. A noter que les classes étant déterminées par le premier feature, les features suivant ne sont que du bruit.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 10):\n",
    "    train_data, train_y, test_data, test_y = generate_data_set(10, i)\n",
    "    nbrs = KNeighborsClassifier(n_neighbors=1).fit(train_data, train_y)\n",
    "    print(sum(nbrs.predict(test_data) == test_y) / len(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qu'observez-vous ? Comment l'expliquez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ecrivez votre réponse ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on fait varier l'ordre de grandeur du premier feature. Cela peut être le cas sur un changement d'unité (par exemple pour de l'énergie, vous varier entre GWh, MWh et KWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scale in (1e-3, 1, 1e3):\n",
    "    print(f\"### scale : {scale} ###\")\n",
    "    for i in range(2, 10):\n",
    "        train_data, train_y, test_data, test_y = generate_data_set(10, i, first_feature_scale = scale)\n",
    "        nbrs = KNeighborsClassifier(n_neighbors=1).fit(train_data, train_y)\n",
    "        print(sum(nbrs.predict(test_data) == test_y) / len(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qu'observez-vous ? Comment l'expliquez-vous ? Est-ce que cela paraît raisonnable ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ecrivez votre réponse ici"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
