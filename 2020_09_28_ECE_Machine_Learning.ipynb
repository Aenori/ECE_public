{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Iris data set et K-Nearest Neighbors\n",
    "\n",
    "Le set des Iris est un classique en machine learning, on a un petit jeu de données (150 éléments) avec 3 variétés d'Iris (Setosa, Versicolour, Virginica) et 4 \"features\" : largeur et longueur des pétales et des sépales.\n",
    "\n",
    "On cherche à développer un classifieur qui soit capable de déterminer de quel type de fleur il s'agit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "print('#' * 25)\n",
    "print(iris.keys())\n",
    "print('#' * 25)\n",
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "# Source : https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "\n",
    "plt.figure(2, figsize=(8, 6))\n",
    "plt.clf()\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1,\n",
    "            edgecolor='k')\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sépare les données en jeu de donnée d'entrainement et de test.\n",
    "A noter que suivant le cas, il peut être important de mélanger les données. Ici on privilégie la simplicité et le fait d'être sur que les 3 classes sont équitablement représentées dans les deux jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.concatenate((iris['data'][:40, :], iris['data'][50:90, :], iris['data'][100:140, :]), axis = 0)\n",
    "training_target = np.concatenate((iris['target'][:40], iris['target'][50:90], iris['target'][100:140]), axis = 0)\n",
    "\n",
    "test_data = np.concatenate((iris['data'][40:50, :], iris['data'][90:100, :], iris['data'][140:, :]), axis = 0)\n",
    "test_target = np.concatenate((iris['target'][40:50], iris['target'][90:100], iris['target'][140:]), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les dimensions pour vérfier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_data.shape)\n",
    "print(training_target.shape)\n",
    "print(test_data.shape)\n",
    "print(test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "nbrs = KNeighborsClassifier(n_neighbors=1).fit(training_data, training_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction == test_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-NN et données générées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def generate_data_set(nb_class, nb_features, nb_elements = 1000, test_ratio = 0.2, first_feature_scale = 1):\n",
    "    all_data = np.random.random((nb_elements, nb_features))\n",
    "    y = np.floor(all_data[:, 0] * nb_class).astype(np.int32)\n",
    "    \n",
    "    all_data[:, 0] *= first_feature_scale\n",
    "    \n",
    "    nb_train = int((1 - test_ratio) * nb_elements)\n",
    "    \n",
    "    return all_data[:nb_train, :], y[:nb_train], all_data[nb_train:, :], y[nb_train:]\n",
    "    \n",
    "train_data, train_y, test_data, test_y = generate_data_set(1000, 5)\n",
    "\n",
    "print((train_data.shape, train_y.shape, test_data.shape, test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 10):\n",
    "    train_data, train_y, test_data, test_y = generate_data_set(10, i, first_feature_scale = 0.01)\n",
    "    nbrs = KNeighborsClassifier(n_neighbors=1).fit(train_data, train_y)\n",
    "    print(sum(nbrs.predict(test_data) == test_y) / len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
